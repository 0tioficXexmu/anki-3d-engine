// Copyright (C) 2009-2018, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki input const UVec2 FB_SIZE
#pragma anki input const UVec2 WORKGROUP_SIZE
#pragma anki input const U32 MAX_STEPS
#pragma anki input const U32 LIGHT_BUFFER_MIP_COUNT

#pragma anki start comp
#include <shaders/Functions.glsl>
#include <shaders/Pack.glsl>
#include <shaders/glsl_cpp_common/Ssr.h>

layout(local_size_x = WORKGROUP_SIZE.x, local_size_y = WORKGROUP_SIZE.y, local_size_z = 1) in;

layout(ANKI_TEX_BINDING(0, 0)) uniform sampler2D u_gbufferRt1;
layout(ANKI_TEX_BINDING(0, 1)) uniform sampler2D u_gbufferRt2;
layout(ANKI_TEX_BINDING(0, 2)) uniform sampler2D u_depthRt;
layout(ANKI_TEX_BINDING(0, 3)) uniform sampler2D u_lightBufferRt;

layout(ANKI_IMAGE_BINDING(0, 0)) writeonly uniform image2D out_img;

layout(ANKI_UBO_BINDING(0, 0), row_major) uniform u_
{
	SsrUniforms u_unis;
};
#define u_prevViewProjMatMulInvViewProjMat u_unis.m_prevViewProjMatMulInvViewProjMat
#define u_near u_unis.m_nearPad3.x
#define u_projMat u_unis.m_projMat
#define u_invProjMat u_unis.m_invProjMat
#define u_normalMat u_unis.m_normalMat

// Note: All calculations in view space
// It returns the UV coordinates of the reflection (xy) and the contrubution factor (z)
Vec3 raymarch(Vec3 r, Vec3 n, Vec3 viewPos, Vec2 uv, F32 depth)
{
	Vec3 p0 = viewPos;

	// Check for view facing reflections [sakibsaikia]
	Vec3 viewDir = normalize(viewPos);
	F32 cameraContribution = 1.0 - smoothstep(0.25, 0.5, dot(-viewDir, r));
	if(cameraContribution <= 0.0)
	{
		return Vec3(0.0);
	}

	// Compute an end point p1. This point is supposed to fall in front of the near plane. Add a small padding to near
	// to avoid having p1 touching the near plane.
	Vec3 p1 = p0 + r * (-p0.z - (u_near + 0.1));

	// Start point
	Vec3 start = Vec3(uv, depth);

	// Project end point
	Vec4 end4 = u_projMat * Vec4(p1, 1.0);
	Vec3 end = end4.xyz / end4.w;
	end.xy = NDC_TO_UV(end.xy);

	// Compute the ray and step size
	Vec3 ray = end - start;
	Vec2 texelDims = abs(ray.xy) * Vec2(FB_SIZE);
	F32 stepSize = length(ray.xy) / max(texelDims.x, texelDims.y);
	ray = normalize(ray);

	// Compute step
	const U32 BIG_STEP_SKIP = 32u;
	U32 stepSkip = BIG_STEP_SKIP;

	const U32 STEP_FRACTION = BIG_STEP_SKIP / (4u + 1u);
	const U32 STEPS_ARR[4] = U32[](STEP_FRACTION, 4 * STEP_FRACTION, 2 * STEP_FRACTION, 3 * STEP_FRACTION);
	U32 l = gl_GlobalInvocationID.x & 1u;
	U32 j = gl_GlobalInvocationID.y & 1u;
	U32 step = STEPS_ARR[l * 2u + j];

	// Iterate
	F32 finalContribution = 0.0;
	Vec3 raySample;
	ANKI_LOOP for(U32 iterations = 0u; iterations < MAX_STEPS; ++iterations)
	{
		raySample = start + ray * (F32(step) * stepSize);

		// Check if it's out of the view
		if(raySample.x <= 0.0 || raySample.y <= 0.0 || raySample.x >= 1.0 || raySample.y >= 1.0)
		{
			break;
		}

		F32 depth = textureLod(u_depthRt, raySample.xy, 0.0).r;

		Bool hit = raySample.z - depth >= 0.0;
		if(!hit)
		{
			step += stepSkip;
		}
		else if(stepSkip > 1)
		{
			step -= BIG_STEP_SKIP - 1u;
			stepSkip = 1u;
		}
		else
		{
			// Found it

			// Re-project previous frame
			Vec4 v4 = u_prevViewProjMatMulInvViewProjMat * Vec4(UV_TO_NDC(raySample.xy), raySample.z, 1.0);
			Vec2 ndc = v4.xy / v4.w;
			raySample.xy = NDC_TO_UV(ndc);

			// Compute the edge contribution
			ndc = abs(ndc);
			F32 screedEdgeContributionFactor = max(ndc.x, ndc.y);
			screedEdgeContributionFactor = 1.0 - screedEdgeContributionFactor * screedEdgeContributionFactor;
			screedEdgeContributionFactor = saturate(screedEdgeContributionFactor);
			finalContribution = cameraContribution * screedEdgeContributionFactor;

			break;
		}
	}

	// Return the traced UV and the contribution factor
	return Vec3(raySample.xy, finalContribution);
}

void main()
{
	if(gl_GlobalInvocationID.x >= FB_SIZE.x || gl_GlobalInvocationID.y >= FB_SIZE.y)
	{
		return;
	}

	Vec2 uv = (Vec2(gl_GlobalInvocationID.xy) + 0.5) / Vec2(FB_SIZE);

	// Read part of the G-buffer
	F32 roughness = readRoughnessFromGBuffer(u_gbufferRt1, uv);
	Vec3 worldNormal = readNormalFromGBuffer(u_gbufferRt2, uv);

	// Get depth
	F32 depth = textureLod(u_depthRt, uv, 0.0).r;

	// Get view pos
	Vec4 viewPos4 = u_invProjMat * Vec4(UV_TO_NDC(uv), depth, 1.0);
	Vec3 viewPos = viewPos4.xyz / viewPos4.w;

	// Compute refl vector
	Vec3 viewDir = normalize(viewPos);
	Vec3 viewNormal = u_normalMat * worldNormal;
	Vec3 reflVec = reflect(viewDir, viewNormal);

	// Raymatch
	Vec3 ssr = raymarch(reflVec, viewNormal, viewPos, uv, depth);
	Vec2 reflUv = ssr.xy;
	F32 factor = ssr.z;

	// Read the reflection
	Vec3 reflColor;
	if(factor > 0.0)
	{
		// Read the refl
		F32 lod = F32(LIGHT_BUFFER_MIP_COUNT - 1u) * roughness;
		reflColor = textureLod(u_lightBufferRt, reflUv, lod).rgb;
		reflColor = clamp(reflColor, 0.0, FLT_MAX); // Fix the value just in case
	}
	else
	{
		reflColor = Vec3(0.0);
	}

	// Store to the image
	imageStore(out_img, ivec2(gl_GlobalInvocationID.xy), Vec4(reflColor * factor, factor));
}
#pragma anki end
